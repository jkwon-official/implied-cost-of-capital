{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wrds\n",
    "from fredapi import Fred\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "\n",
    "root = '/Users/jingookwon/Dropbox/CapitalBudgetingHistory/Annual Reports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "wrds_username = 'jingookwon'\n",
    "wrds_password = 't47k!xXhvsaje!R'\n",
    "fred_api_key = 'ccc8d4225575d294c70da7e99d782b17'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae00b6d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334dc53",
   "metadata": {},
   "source": [
    "## FF49 Industry Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b20527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff49_fun(sic):\n",
    "    \"\"\"\n",
    "    Map SIC codes to FF49 industry classifications\n",
    "\n",
    "    Parameters:\n",
    "    sic: SIC code; need to be int, float, or array-like\n",
    "\n",
    "    Returns:\n",
    "    int, float, or array-like\n",
    "        FF49 industry classification (1-49) or NaN for unmatched SIC codes\n",
    "    \"\"\"\n",
    "    if np.isscalar(sic):\n",
    "        return _ff49_single(sic)\n",
    "    else:\n",
    "        sic_array = np.array(sic)\n",
    "        result = np.full(sic_array.shape, np.nan)\n",
    "\n",
    "        for i, s in enumerate(sic_array.flat):\n",
    "            result.flat[i] = _ff49_single(s)\n",
    "    \n",
    "        return result\n",
    "\n",
    "def _ff49_single(sic):\n",
    "    \"\"\"Helper function for single SIC code mapping\"\"\"\n",
    "    if pd.isna(sic):\n",
    "        return np.nan\n",
    "    \n",
    "    # Industry 1: Agriculture\n",
    "    if (sic == 2048 or (100 <= sic <= 299) or (700 <= sic <= 799) or \n",
    "        (910 <= sic <= 919)):\n",
    "        return 1\n",
    "    \n",
    "    # Industry 2: Food Products  \n",
    "    elif (sic in [2095, 2098, 2099] or (2000 <= sic <= 2046) or \n",
    "          (2050 <= sic <= 2063) or (2070 <= sic <= 2079) or \n",
    "          (2090 <= sic <= 2092)):\n",
    "        return 2\n",
    "    \n",
    "    # Industry 3: Candy & Soda\n",
    "    elif (sic in [2086, 2087, 2096, 2097] or (2064 <= sic <= 2068)):\n",
    "        return 3\n",
    "    \n",
    "    # Industry 4: Beer & Liquor\n",
    "    elif (sic == 2080 or (2082 <= sic <= 2085)):\n",
    "        return 4\n",
    "    \n",
    "    # Industry 5: Tobacco Products\n",
    "    elif (2100 <= sic <= 2199):\n",
    "        return 5\n",
    "    \n",
    "    # Industry 6: Recreation\n",
    "    elif (sic in [3732, 3930, 3931] or (920 <= sic <= 999) or \n",
    "          (3650 <= sic <= 3652) or (3940 <= sic <= 3949)):\n",
    "        return 6\n",
    "    \n",
    "    # Industry 7: Entertainment\n",
    "    elif (sic in [7840, 7841, 7900, 7910, 7911, 7980] or \n",
    "          (7800 <= sic <= 7833) or (7920 <= sic <= 7933) or \n",
    "          (7940 <= sic <= 7949) or (7990 <= sic <= 7999)):\n",
    "        return 7\n",
    "    \n",
    "    # Industry 8: Printing and Publishing\n",
    "    elif (sic in [2770, 2771] or (2700 <= sic <= 2749) or \n",
    "          (2780 <= sic <= 2799)):\n",
    "        return 8\n",
    "    \n",
    "    # Industry 9: Consumer Goods\n",
    "    elif (sic in [2047, 2391, 2392, 3160, 3161, 3229, 3260, 3262, 3263, \n",
    "                  3269, 3230, 3231, 3750, 3751, 3800, 3860, 3861, 3910, \n",
    "                  3911, 3914, 3915, 3991, 3995] or \n",
    "          (2510 <= sic <= 2519) or (2590 <= sic <= 2599) or \n",
    "          (2840 <= sic <= 2844) or (3170 <= sic <= 3172) or \n",
    "          (3190 <= sic <= 3199) or (3630 <= sic <= 3639) or \n",
    "          (3870 <= sic <= 3873) or (3960 <= sic <= 3962)):\n",
    "        return 9\n",
    "    \n",
    "    # Industry 10: Apparel\n",
    "    elif (sic in [3020, 3021, 3130, 3131, 3150, 3151] or \n",
    "          (2300 <= sic <= 2390) or (3100 <= sic <= 3111) or \n",
    "          (3140 <= sic <= 3149) or (3963 <= sic <= 3965)):\n",
    "        return 10\n",
    "    \n",
    "    # Industry 11: Healthcare\n",
    "    elif (8000 <= sic <= 8099):\n",
    "        return 11\n",
    "    \n",
    "    # Industry 12: Medical Equipment\n",
    "    elif (sic in [3693, 3850, 3851] or (3840 <= sic <= 3849)):\n",
    "        return 12\n",
    "    \n",
    "    # Industry 13: Pharmaceutical Products\n",
    "    elif (sic in [2830, 2831] or (2833 <= sic <= 2836)):\n",
    "        return 13\n",
    "    \n",
    "    # Industry 14: Chemicals\n",
    "    elif ((2800 <= sic <= 2829) or (2850 <= sic <= 2879) or \n",
    "          (2890 <= sic <= 2899)):\n",
    "        return 14\n",
    "    \n",
    "    # Industry 15: Rubber and Plastic Products\n",
    "    elif (sic in [3031, 3041] or (3050 <= sic <= 3053) or \n",
    "          (3060 <= sic <= 3099)):\n",
    "        return 15\n",
    "    \n",
    "    # Industry 16: Textiles\n",
    "    elif ((2200 <= sic <= 2284) or (2290 <= sic <= 2295) or \n",
    "          (2297 <= sic <= 2299) or (2393 <= sic <= 2395) or \n",
    "          (2397 <= sic <= 2399)):\n",
    "        return 16\n",
    "    \n",
    "    # Industry 17: Construction Materials\n",
    "    elif (sic in [2660, 2661, 3200, 3210, 3211, 3240, 3241, 3261, 3264, \n",
    "                  3280, 3281, 3446, 3996] or \n",
    "          (800 <= sic <= 899) or (2400 <= sic <= 2439) or \n",
    "          (2450 <= sic <= 2459) or (2490 <= sic <= 2499) or \n",
    "          (2950 <= sic <= 2952) or (3250 <= sic <= 3259) or \n",
    "          (3270 <= sic <= 3275) or (3290 <= sic <= 3293) or \n",
    "          (3295 <= sic <= 3299) or (3420 <= sic <= 3429) or \n",
    "          (3430 <= sic <= 3433) or (3440 <= sic <= 3442) or \n",
    "          (3448 <= sic <= 3452) or (3490 <= sic <= 3499)):\n",
    "        return 17\n",
    "    \n",
    "    # Industry 18: Construction\n",
    "    elif ((1500 <= sic <= 1511) or (1520 <= sic <= 1549) or \n",
    "          (1600 <= sic <= 1799)):\n",
    "        return 18\n",
    "    \n",
    "    # Industry 19: Steel Works Etc\n",
    "    elif (sic == 3300 or (3310 <= sic <= 3317) or (3320 <= sic <= 3325) or \n",
    "          (3330 <= sic <= 3341) or (3350 <= sic <= 3357) or \n",
    "          (3360 <= sic <= 3379) or (3390 <= sic <= 3399)):\n",
    "        return 19\n",
    "    \n",
    "    # Industry 20: Fabricated Products\n",
    "    elif (sic in [3400, 3443, 3444] or (3460 <= sic <= 3479)):\n",
    "        return 20\n",
    "    \n",
    "    # Industry 21: Machinery\n",
    "    elif (sic in [3538, 3585, 3586] or (3510 <= sic <= 3536) or \n",
    "          (3540 <= sic <= 3569) or (3580 <= sic <= 3582) or \n",
    "          (3589 <= sic <= 3599)):\n",
    "        return 21\n",
    "    \n",
    "    # Industry 22: Electrical Equipment\n",
    "    elif (sic in [3600, 3620, 3621, 3648, 3649, 3660, 3699] or \n",
    "          (3610 <= sic <= 3613) or (3623 <= sic <= 3629) or \n",
    "          (3640 <= sic <= 3646) or (3690 <= sic <= 3692)):\n",
    "        return 22\n",
    "    \n",
    "    # Industry 23: Automobiles and Trucks\n",
    "    elif (sic in [2296, 2396, 3010, 3011, 3537, 3647, 3694, 3700, 3710, \n",
    "                  3711, 3799] or (3713 <= sic <= 3716) or \n",
    "          (3790 <= sic <= 3792)):\n",
    "        return 23\n",
    "    \n",
    "    # Industry 24: Aircraft\n",
    "    elif (sic in [3720, 3721, 3728, 3729] or (3723 <= sic <= 3725)):\n",
    "        return 24\n",
    "    \n",
    "    # Industry 25: Shipbuilding, Railroad Equipment\n",
    "    elif (sic in [3730, 3731] or (3740 <= sic <= 3743)):\n",
    "        return 25\n",
    "    \n",
    "    # Industry 26: Defense\n",
    "    elif (sic == 3795 or (3760 <= sic <= 3769) or (3480 <= sic <= 3489)):\n",
    "        return 26\n",
    "    \n",
    "    # Industry 27: Precious Metals\n",
    "    elif (1040 <= sic <= 1049):\n",
    "        return 27\n",
    "    \n",
    "    # Industry 28: Non-Metallic and Industrial Metal Mining\n",
    "    elif ((1000 <= sic <= 1039) or (1050 <= sic <= 1119) or \n",
    "          (1400 <= sic <= 1499)):\n",
    "        return 28\n",
    "    \n",
    "    # Industry 29: Coal\n",
    "    elif (1200 <= sic <= 1299):\n",
    "        return 29\n",
    "    \n",
    "    # Industry 30: Petroleum and Natural Gas\n",
    "    elif (sic in [1300, 1389] or (1310 <= sic <= 1339) or \n",
    "          (1370 <= sic <= 1382) or (2900 <= sic <= 2912) or \n",
    "          (2990 <= sic <= 2999)):\n",
    "        return 30\n",
    "    \n",
    "    # Industry 31: Utilities\n",
    "    elif (sic in [4900, 4910, 4911, 4939] or (4920 <= sic <= 4925) or \n",
    "          (4930 <= sic <= 4932) or (4940 <= sic <= 4942)):\n",
    "        return 31\n",
    "    \n",
    "    # Industry 32: Communication\n",
    "    elif (sic in [4800, 4899] or (4810 <= sic <= 4813) or \n",
    "          (4820 <= sic <= 4822) or (4830 <= sic <= 4841) or \n",
    "          (4880 <= sic <= 4892)):\n",
    "        return 32\n",
    "    \n",
    "    # Industry 33: Personal Services\n",
    "    elif (sic in [7020, 7021, 7200, 7230, 7231, 7240, 7241, 7250, 7251, \n",
    "                  7395, 7500, 7600, 7620, 7622, 7623, 7640, 7641] or \n",
    "          (7030 <= sic <= 7033) or (7210 <= sic <= 7212) or \n",
    "          (7214 <= sic <= 7217) or (7219 <= sic <= 7221) or \n",
    "          (7260 <= sic <= 7299) or (7520 <= sic <= 7549) or \n",
    "          (7629 <= sic <= 7631) or (7690 <= sic <= 7699) or \n",
    "          (8100 <= sic <= 8499) or (8600 <= sic <= 8699) or \n",
    "          (8800 <= sic <= 8899) or (7510 <= sic <= 7515)):\n",
    "        return 33\n",
    "    \n",
    "    # Industry 34: Business Services\n",
    "    elif (sic in [3993, 7218, 7300, 7374, 7396, 7397, 7399, 7519, 8700, \n",
    "                  8720, 8721] or (2750 <= sic <= 2759) or \n",
    "          (7310 <= sic <= 7342) or (7349 <= sic <= 7353) or \n",
    "          (7359 <= sic <= 7369) or (7376 <= sic <= 7385) or \n",
    "          (7389 <= sic <= 7394) or (8710 <= sic <= 8713) or \n",
    "          (8730 <= sic <= 8734) or (8740 <= sic <= 8748) or \n",
    "          (8900 <= sic <= 8911) or (8920 <= sic <= 8999) or \n",
    "          (4220 <= sic <= 4229)):\n",
    "        return 34\n",
    "    \n",
    "    # Industry 35: Computers\n",
    "    elif (sic == 3695 or (3570 <= sic <= 3579) or (3680 <= sic <= 3689)):\n",
    "        return 35\n",
    "    \n",
    "    # Industry 36: Computer Software\n",
    "    elif (sic == 7375 or (7370 <= sic <= 7373)):\n",
    "        return 36\n",
    "    \n",
    "    # Industry 37: Electronic Equipment\n",
    "    elif (sic in [3622, 3810, 3812] or (3661 <= sic <= 3666) or \n",
    "          (3669 <= sic <= 3679)):\n",
    "        return 37\n",
    "    \n",
    "    # Industry 38: Measuring and Control Equipment\n",
    "    elif (sic == 3811 or (3820 <= sic <= 3827) or (3829 <= sic <= 3839)):\n",
    "        return 38\n",
    "    \n",
    "    # Industry 39: Business Supplies\n",
    "    elif (sic in [2760, 2761] or (2520 <= sic <= 2549) or \n",
    "          (2600 <= sic <= 2639) or (2670 <= sic <= 2699) or \n",
    "          (3950 <= sic <= 3955)):\n",
    "        return 39\n",
    "    \n",
    "    # Industry 40: Shipping Containers\n",
    "    elif (sic in [3220, 3221] or (2440 <= sic <= 2449) or \n",
    "          (2640 <= sic <= 2659) or (3410 <= sic <= 3412)):\n",
    "        return 40\n",
    "    \n",
    "    # Industry 41: Transportation\n",
    "    elif (sic in [4100, 4130, 4131, 4150, 4151, 4230, 4231, 4780, 4789] or \n",
    "          (4000 <= sic <= 4013) or (4040 <= sic <= 4049) or \n",
    "          (4110 <= sic <= 4121) or (4140 <= sic <= 4142) or \n",
    "          (4170 <= sic <= 4173) or (4190 <= sic <= 4200) or \n",
    "          (4210 <= sic <= 4219) or (4240 <= sic <= 4249) or \n",
    "          (4400 <= sic <= 4700) or (4710 <= sic <= 4712) or \n",
    "          (4720 <= sic <= 4749) or (4782 <= sic <= 4785)):\n",
    "        return 41\n",
    "    \n",
    "    # Industry 42: Wholesale\n",
    "    elif (sic in [5000, 5099, 5100] or (5010 <= sic <= 5015) or \n",
    "          (5020 <= sic <= 5023) or (5030 <= sic <= 5060) or \n",
    "          (5063 <= sic <= 5065) or (5070 <= sic <= 5078) or \n",
    "          (5080 <= sic <= 5088) or (5090 <= sic <= 5094) or \n",
    "          (5110 <= sic <= 5113) or (5120 <= sic <= 5122) or \n",
    "          (5130 <= sic <= 5172) or (5180 <= sic <= 5182) or \n",
    "          (5190 <= sic <= 5199)):\n",
    "        return 42\n",
    "    \n",
    "    # Industry 43: Retail\n",
    "    elif (sic in [5200, 5250, 5251, 5260, 5261, 5270, 5271, 5300, 5310, \n",
    "                  5311, 5320, 5330, 5331, 5334, 5900, 5999] or \n",
    "          (5210 <= sic <= 5231) or (5340 <= sic <= 5349) or \n",
    "          (5390 <= sic <= 5400) or (5410 <= sic <= 5412) or \n",
    "          (5420 <= sic <= 5469) or (5490 <= sic <= 5500) or \n",
    "          (5510 <= sic <= 5579) or (5590 <= sic <= 5700) or \n",
    "          (5710 <= sic <= 5722) or (5730 <= sic <= 5736) or \n",
    "          (5750 <= sic <= 5799) or (5910 <= sic <= 5912) or \n",
    "          (5920 <= sic <= 5932) or (5940 <= sic <= 5990) or \n",
    "          (5992 <= sic <= 5995)):\n",
    "        return 43\n",
    "    \n",
    "    # Industry 44: Restaurants, Hotels, Motels\n",
    "    elif (sic in [7000, 7213] or (5800 <= sic <= 5829) or \n",
    "          (5890 <= sic <= 5899) or (7010 <= sic <= 7019) or \n",
    "          (7040 <= sic <= 7049)):\n",
    "        return 44\n",
    "    \n",
    "    # Industry 45: Banking\n",
    "    elif (sic == 6000 or (6010 <= sic <= 6036) or (6040 <= sic <= 6062) or \n",
    "          (6080 <= sic <= 6082) or (6090 <= sic <= 6100) or \n",
    "          (6110 <= sic <= 6113) or (6120 <= sic <= 6179) or \n",
    "          (6190 <= sic <= 6199)):\n",
    "        return 45\n",
    "    \n",
    "    # Industry 46: Insurance\n",
    "    elif (sic in [6300, 6350, 6351, 6360, 6361] or \n",
    "          (6310 <= sic <= 6331) or (6370 <= sic <= 6379) or \n",
    "          (6390 <= sic <= 6411)):\n",
    "        return 46\n",
    "    \n",
    "    # Industry 47: Real Estate\n",
    "    elif (sic in [6500, 6510, 6540, 6541, 6610, 6611] or \n",
    "          (6512 <= sic <= 6515) or (6517 <= sic <= 6532) or \n",
    "          (6550 <= sic <= 6553) or (6590 <= sic <= 6599)):\n",
    "        return 47\n",
    "    \n",
    "    # Industry 48: Trading\n",
    "    elif (sic in [6700, 6798, 6799] or (6200 <= sic <= 6299) or \n",
    "          (6710 <= sic <= 6726) or (6730 <= sic <= 6733) or \n",
    "          (6740 <= sic <= 6779) or (6790 <= sic <= 6795)):\n",
    "        return 48\n",
    "    \n",
    "    # Industry 49: Almost Nothing\n",
    "    elif (sic in [4970, 4971, 4990, 4991] or (4950 <= sic <= 4961)):\n",
    "        return 49\n",
    "    \n",
    "    # Default case - unmatched SIC codes\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b319ad9",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_icc_data(daily_p, epsf, epsa, acc_g, acc_us, po_pref, bps, dps, rf10, ff49_ind, funda_g, funda):\n",
    "    \"\"\"\n",
    "    Prepare data for ICC calculation\n",
    "\n",
    "    Parameters:\n",
    "    daily_p: pd.DataFrame\n",
    "        Daily price data\n",
    "    epsf: pd.DataFrame\n",
    "        EPS forecasts from IBES\n",
    "    epsa: pd.DataFrame\n",
    "        EPS actuals from IBES\n",
    "    acc_g: pd.DataFrame\n",
    "        Global accounting data\n",
    "    acc_us: pd.DataFrame\n",
    "        US accounting data\n",
    "    po_pref: str\n",
    "        Preference for payout ratio source ('g_funda' or 'funda')\n",
    "    bps: pd.DataFrame\n",
    "        Book value per share data\n",
    "    dps: pd.DataFrame\n",
    "        Dividends per share data from IBES\n",
    "    rf10: pd.DataFrame\n",
    "        10-year risk-free data from FRED\n",
    "    ff49_ind: pd.DataFrame\n",
    "        FF49 industry classification\n",
    "    funda_g: pd.DataFrame\n",
    "        Global fundamental data\n",
    "    funda: pd.DataFrame\n",
    "        US fundamental data\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        Prepared data for ICC calculation\n",
    "    \"\"\"\n",
    "\n",
    "    # Processing EPS forecasts\n",
    "    epsf_filtered = epsf[(epsf['measure'] == 'EPS') & (epsf['fpi'].isin([1,2]))].copy()\n",
    "    epsf_filtered['fpi_label'] = 'eps' + epsf_filtered['fpi'].astype(str)\n",
    "\n",
    "    # Pivot to wide\n",
    "    epsf_st = epsf_filtered.pivot_table(\n",
    "        index = ['id', 'datadate'],\n",
    "        columns = 'fpi_label',\n",
    "        values = 'value_adj',\n",
    "        aggfunc = 'first'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Fill missing eps2 with 15% growth assumption\n",
    "    epsf_st['eps2'] = epsf_st['eps2'].fillna(epsf_st['eps1'] * 1.15)\n",
    "\n",
    "    # Coverage calculation (12-month rolling average)\n",
    "    numest_data = epsf[(epsf['measure'] == 'EPS') & (epsf['fpi'] == 1)][['id', 'datadate', 'numest']].copy()\n",
    "\n",
    "    # Get unique dates and compute rolling coverage\n",
    "    ibes_dates = sorted(numest_data['datadate'].unique())\n",
    "    numest_list = []\n",
    "\n",
    "    for i in range(11, len(ibes_dates)):\n",
    "        start_date = ibes_dates[i - 11]\n",
    "        end_date = ibes_dates[i]\n",
    "\n",
    "        temp_data = numest_data[\n",
    "            (numest_data['datadate'] >= start_date) & (numest_data['datadate'] <= end_date)\n",
    "        ].groupby('id').agg({\n",
    "            'numest': ['count', 'mean']\n",
    "        }).reset_index()\n",
    "\n",
    "        temp_data.columns = ['id', 'n', 'numest1_avg']\n",
    "        temp_data = temp_data[temp_data['n'] == 12]\n",
    "        temp_data['datadate'] = end_date\n",
    "        numest_list.append(temp_data[['id', 'datadate', 'numest1_avg']])\n",
    "    \n",
    "    numest = pd.concat(numest_list, ignore_index=True)\n",
    "\n",
    "    # LTG forecasts\n",
    "    epsf_ltg = epsf[(epsf['measure'] == 'LTG') & (epsf['fpi'] == 0)].copy()\n",
    "    epsf_ltg['ltg'] = epsf_ltg['medest'] / 100\n",
    "    epsf_ltg = epsf_ltg[['id', 'datadate', 'ltg']]\n",
    "\n",
    "    # Processing EPS actuals\n",
    "    epsa_filtered = epsa[(epsa['measure'] == 'EPS') & (epsa['pdicity'] == 'ANN') \n",
    "                         & (epsa['value_adj'].notna()) & np.isfinite(epsa['value_adj'])].copy()\n",
    "    epsa_ann = epsa_filtered[['id', 'datadate', 'value_adj']].copy()\n",
    "    epsa_ann.columns = ['id', 'start', 'eps0']\n",
    "    epsa_ann = epsa_ann.sort_values(['id', 'start'])\n",
    "\n",
    "    # Create end dates\n",
    "    epsa_ann['end'] = epsa_ann.groupby('id')['start'].shift(-1) - timedelta(days=1)\n",
    "    epsa_ann['end'] = epsa_ann['end'].fillna(\n",
    "        epsa_ann['start'] + relativedelta(months=13) - timedelta(days=1)\n",
    "    )\n",
    "\n",
    "    # DPS estimates from IBES\n",
    "    dps_ib = dps[['id', 'datadate', 'value_adj']].copy()\n",
    "    dps_ib.columns = ['id', 'start', 'ib_dps1']\n",
    "\n",
    "    # Payout ratio from Compustat\n",
    "    acc_g_subset = acc_g[['gvkey', 'datadate', 'at', 'dvt', 'ib']].copy()\n",
    "    acc_g_subset['type'] = 'g_funda'\n",
    "\n",
    "    acc_us_subset = acc_us[['gvkey', 'datadate', 'at', 'dvt', 'ib']].copy()\n",
    "    acc_us_subset['type'] = 'funda'\n",
    "\n",
    "    po_comp = pd.concat([acc_g_subset, acc_us_subset], ignore_index=True)\n",
    "    po_comp = po_comp[po_comp['at'] > 0] # Non-negative assets\n",
    "\n",
    "    # Compute payout ratio\n",
    "    po_comp['po'] = np.where(\n",
    "        po_comp['ib'] > 0, po_comp['dvt'] / po_comp['ib'], po_comp['dvt'] / (po_comp['at'] * 0.06)\n",
    "    )\n",
    "\n",
    "    # Handle duplicates\n",
    "    po_comp['n'] = po_comp.groupby(['gvkey', 'datadate'])['gvkey'].transform('count')\n",
    "    po_comp = po_comp[\n",
    "        (po_comp['n'] == 1) | ((po_comp['n'] == 2) & (po_comp['type'] == po_pref))\n",
    "    ].drop(['type', 'n'], axis=1)\n",
    "\n",
    "    po_comp = po_comp.dropna(subset=['po']).sort_values(['gvkey', 'datadate'])\n",
    "\n",
    "    # Add publication dates (4-month lag)\n",
    "    po_comp['public_date'] = pd.to_datetime(po_comp['datadate']) + relativedelta(months=4)\n",
    "    po_comp['start'] = po_comp['public_date']\n",
    "    po_comp['end'] = po_comp.groupby('gvkey')['public_date'].shift(-1) - timedelta(days=1)\n",
    "    po_comp['end'] = po_comp['end'].fillna(\n",
    "        po_comp['start'] + relativedelta(years=1) - timedelta(days=1)\n",
    "    )\n",
    "\n",
    "    # Winsorize\n",
    "    p01 = po_comp['po'].quantile(0.01)\n",
    "    p99 = po_comp['po'].quantile(0.99)\n",
    "    po_comp['po'] = po_comp['po'].clip(lower=p01, upper=p99)\n",
    "    po_comp = po_comp[['gvkey', 'start', 'end', 'po']]\n",
    "\n",
    "    # Industry ROE calculation\n",
    "    funda_g_subset = funda_g[['gvkey', 'datadate', 'curcd', 'fx', 'ff49', 'seq', 'ib']].copy()\n",
    "    funda_g_subset['int'] = True\n",
    "\n",
    "    funda_subset = funda[['gvkey', 'datadate', 'curcd', 'fx', 'ff49', 'seq', 'ib']].copy()\n",
    "    funda_subset['int'] = False\n",
    "\n",
    "    acc = pd.concat([funda_g_subset, funda_subset], ignore_index=True)\n",
    "    roe_comp = acc.sort_values(['gvkey', 'int', 'datadate']).copy()\n",
    "\n",
    "    # Compute ROE\n",
    "    roe_comp['roe'] = roe_comp.groupby(['gvkey', 'int'])['ib'] / roe_comp.groupby(['gvkey', 'int'])['seq'].shift(1)\n",
    "    roe_comp['roe_usd'] = (roe_comp['ib'] * roe_comp['fx']) / (roe_comp.groupby(['gvkey', 'int'])['seq'].shift(1) * roe_comp.groupby(['gvkey', 'int'])['fx'].shift(1))\n",
    "\n",
    "    # Currency changes\n",
    "    roe_comp['curcd_lag'] = roe_comp.groupby(['gvkey', 'int'])['curcd'].shift(1)\n",
    "    roe_comp.loc[roe_comp['curcd'] != roe_comp['curcd_lag'], 'roe'] = roe_comp['roe_usd']\n",
    "    \n",
    "    # Check year differences\n",
    "    roe_comp['yr_diff'] = (roe_comp['datadate'] - roe_comp.groupby(['gvkey', 'int'])['datadate'].shift(1)).dt.days\n",
    "    roe_comp = roe_comp[roe_comp['yr_diff'].between(365, 366, inclusive='both')]\n",
    "    \n",
    "    # Filter positive ROE and valid industry\n",
    "    roe_comp = roe_comp[(roe_comp['roe'] > 0) & roe_comp['ff49'].notna()]\n",
    "    \n",
    "    # Handle duplicates (prefer international)\n",
    "    roe_comp['n'] = roe_comp.groupby(['gvkey', 'datadate'])['gvkey'].transform('count')\n",
    "    roe_comp = roe_comp[(roe_comp['n'] == 1) | ((roe_comp['n'] == 2) & (roe_comp['int'] == True))]\n",
    "    \n",
    "    # Calculate industry ROE (10-year rolling median)\n",
    "    roe_comp['public_date'] = pd.to_datetime(roe_comp['datadate']) + relativedelta(months=4)\n",
    "    \n",
    "    unique_dates = sorted(epsf_st['datadate'].unique())\n",
    "    roe_industry_list = []\n",
    "    \n",
    "    for date in unique_dates:\n",
    "        date = pd.to_datetime(date)\n",
    "        start_window = date - relativedelta(years=10)\n",
    "        \n",
    "        temp_roe = roe_comp[\n",
    "            (roe_comp['public_date'] >= start_window) & \n",
    "            (roe_comp['public_date'] <= date)\n",
    "        ].groupby('ff49')['roe'].agg(['count', 'median']).reset_index()\n",
    "        \n",
    "        temp_roe.columns = ['ff49', 'n', 'roe_ind']\n",
    "        temp_roe['datadate'] = date\n",
    "        roe_industry_list.append(temp_roe[['ff49', 'datadate', 'roe_ind']])\n",
    "    \n",
    "    roe_comp_final = pd.concat(roe_industry_list, ignore_index=True)\n",
    "    \n",
    "    # Winsorize industry ROE\n",
    "    p01_roe = roe_comp_final['roe_ind'].quantile(0.01)\n",
    "    p99_roe = roe_comp_final['roe_ind'].quantile(0.99)\n",
    "    roe_comp_final['roe_ind'] = roe_comp_final['roe_ind'].clip(p01_roe, p99_roe)\n",
    "    \n",
    "    # Book-per-share data\n",
    "    bps0 = bps[['id', 'datadate', 'bps_adj']].copy()\n",
    "    bps0['start'] = pd.to_datetime(bps0['datadate']) + relativedelta(months=4)\n",
    "    bps0['end'] = bps0.groupby('id')['start'].shift(-1) - timedelta(days=1)\n",
    "    bps0['end'] = bps0['end'].fillna(bps0['start'] + relativedelta(months=12) - timedelta(days=1))\n",
    "    bps0 = bps0.rename(columns={'bps_adj': 'bps0'})\n",
    "    bps0 = bps0[['id', 'start', 'end', 'bps0']]\n",
    "    \n",
    "    # Combine data\n",
    "    icc_data = pd.merge(epsf_st, daily_p, on=['id', 'datadate'], how='inner')\n",
    "    \n",
    "    # Screen: Require EPS1 and Price\n",
    "    icc_data = icc_data[icc_data['prc_adj'].notna() & icc_data['eps1'].notna()]\n",
    "    \n",
    "    n_start = len(icc_data)\n",
    "    \n",
    "    # Add remaining data with left joins\n",
    "    icc_data = pd.merge(icc_data, numest, on=['id', 'datadate'], how='left')\n",
    "    icc_data = pd.merge(icc_data, epsf_ltg, on=['id', 'datadate'], how='left')\n",
    "    icc_data = pd.merge(icc_data, dps_ib, on=['id', 'datadate'], how='left')\n",
    "    \n",
    "    # Time-based merges (equivalent to non-equi joins in data.table)\n",
    "    def merge_time_range(left_df, right_df, left_key, right_key, date_col):\n",
    "        \"\"\"Helper function for time-range merges\"\"\"\n",
    "        result_list = []\n",
    "        for _, row in left_df.iterrows():\n",
    "            merge_date = row[date_col]\n",
    "            matching_rows = right_df[\n",
    "                (right_df[right_key] == row[left_key]) &\n",
    "                (right_df['start'] <= merge_date) &\n",
    "                (right_df['end'] >= merge_date)\n",
    "            ]\n",
    "            if not matching_rows.empty:\n",
    "                merged_row = row.to_dict()\n",
    "                merged_row.update(matching_rows.iloc[0].to_dict())\n",
    "                result_list.append(merged_row)\n",
    "            else:\n",
    "                merged_row = row.to_dict()\n",
    "                # Add NaN values for missing columns\n",
    "                for col in right_df.columns:\n",
    "                    if col not in ['start', 'end', right_key]:\n",
    "                        merged_row[col] = np.nan\n",
    "                result_list.append(merged_row)\n",
    "        \n",
    "        return pd.DataFrame(result_list)\n",
    "    \n",
    "    # Merge payout ratios\n",
    "    icc_data = merge_time_range(icc_data, po_comp, 'gvkey', 'gvkey', 'datadate')\n",
    "    \n",
    "    # Merge book value per share\n",
    "    icc_data = merge_time_range(icc_data, bps0, 'id', 'id', 'datadate')\n",
    "    \n",
    "    # Merge EPS actuals\n",
    "    icc_data = merge_time_range(icc_data, epsa_ann, 'id', 'id', 'datadate')\n",
    "    \n",
    "    # Merge risk-free rates\n",
    "    rf10_temp = rf10.copy()\n",
    "    rf10_temp = merge_time_range(icc_data[['datadate']], rf10_temp, 'datadate', 'datadate', 'datadate')\n",
    "    icc_data = pd.merge(icc_data, rf10_temp[['datadate', 'rf10']], on='datadate', how='left')\n",
    "    \n",
    "    # Merge industry classifications\n",
    "    icc_data = merge_time_range(icc_data, ff49_ind, 'gvkey', 'gvkey', 'datadate')\n",
    "    \n",
    "    # Merge industry ROE\n",
    "    icc_data = pd.merge(icc_data, roe_comp_final, on=['ff49', 'datadate'], how='left')\n",
    "    \n",
    "    # Check for duplicates\n",
    "    if len(icc_data) != n_start:\n",
    "        warnings.warn(\"DATA HAS DUPLICATES\")\n",
    "    \n",
    "    return icc_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6ce7f",
   "metadata": {},
   "source": [
    "## Ohlson-Juettner (2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbeb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_oj_fun(data):\n",
    "    \"\"\"\n",
    "    Calculate Ohlson-Juettner (2005) implied cost of capital.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame containing required variables: eps1, eps2, ltg, po, \n",
    "        prc_adj, rf10, id, datadate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with id, datadate, and icc_oj columns\n",
    "    \"\"\"\n",
    "    # Filter for required variables (equivalent to data.table filtering)\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'po', 'prc_adj', 'rf10', \n",
    "                     'id', 'datadate']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter rows where all required variables are not null\n",
    "    oj = data.dropna(subset=['eps1', 'eps2', 'ltg', 'po'])[\n",
    "        ['id', 'datadate', 'prc_adj', 'rf10', 'po', 'eps1', 'eps2', 'ltg']\n",
    "    ].copy()\n",
    "    \n",
    "    # Risk premium calculation (rf10 minus 3% equity premium)\n",
    "    oj['gam_min1'] = oj['rf10'] - 0.03\n",
    "    \n",
    "    # Intermediate calculation A\n",
    "    oj['A'] = 0.5 * (oj['gam_min1'] + oj['eps1'] * oj['po'] / oj['prc_adj'])\n",
    "    \n",
    "    # Short-term growth rate calculation\n",
    "    # Max ensures that STG >= LTG (see p. 450 of Mohanram and Gode)\n",
    "    stg_calc = ((oj['eps2'] - oj['eps1']) / oj['eps1'] * oj['ltg']) ** 0.5\n",
    "    oj['stg'] = np.maximum(stg_calc, oj['ltg'])\n",
    "    \n",
    "    # Ohlson-Juettner ICC calculation\n",
    "    oj['icc_oj'] = (oj['A'] + \n",
    "                    np.sqrt(oj['A']**2 + \n",
    "                           oj['eps1'] / oj['prc_adj'] * \n",
    "                           (oj['stg'] - oj['gam_min1'])))\n",
    "    \n",
    "    # Return only required columns\n",
    "    return oj[['id', 'datadate', 'icc_oj']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fd3e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input rows: 1000\n",
      "Output rows: 558\n",
      "Average ICC_OJ: 0.0901\n",
      "ICC_OJ range: 0.0244 to 0.2772\n",
      "\n",
      "First 5 results:\n",
      "   id   datadate    icc_oj\n",
      "2   2 2020-01-03  0.088489\n",
      "3   3 2020-01-04  0.129152\n",
      "5   5 2020-01-06  0.112482\n",
      "6   6 2020-01-07  0.096892\n",
      "7   7 2020-01-08  0.090375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def icc_oj_fun(data):\n",
    "    \"\"\"\n",
    "    Calculate Ohlson-Juettner (2005) implied cost of capital.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame containing required variables: eps1, eps2, ltg, po, \n",
    "        prc_adj, rf10, id, datadate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with id, datadate, and icc_oj columns\n",
    "    \"\"\"\n",
    "    # Filter for required variables (equivalent to data.table filtering)\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'po', 'prc_adj', 'rf10', \n",
    "                     'id', 'datadate']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter rows where all required variables are not null\n",
    "    oj = data.dropna(subset=['eps1', 'eps2', 'ltg', 'po'])[\n",
    "        ['id', 'datadate', 'prc_adj', 'rf10', 'po', 'eps1', 'eps2', 'ltg']\n",
    "    ].copy()\n",
    "    \n",
    "    # Risk premium calculation (rf10 minus 3% equity premium)\n",
    "    oj['gam_min1'] = oj['rf10'] - 0.03\n",
    "    \n",
    "    # Intermediate calculation A\n",
    "    oj['A'] = 0.5 * (oj['gam_min1'] + oj['eps1'] * oj['po'] / oj['prc_adj'])\n",
    "    \n",
    "    # Short-term growth rate calculation\n",
    "    # Max ensures that STG >= LTG (see p. 450 of Mohanram and Gode)\n",
    "    stg_calc = ((oj['eps2'] - oj['eps1']) / oj['eps1'] * oj['ltg']) ** 0.5\n",
    "    oj['stg'] = np.maximum(stg_calc, oj['ltg'])\n",
    "    \n",
    "    # Ohlson-Juettner ICC calculation\n",
    "    oj['icc_oj'] = (oj['A'] + \n",
    "                    np.sqrt(oj['A']**2 + \n",
    "                           oj['eps1'] / oj['prc_adj'] * \n",
    "                           (oj['stg'] - oj['gam_min1'])))\n",
    "    \n",
    "    # Return only required columns\n",
    "    return oj[['id', 'datadate', 'icc_oj']]\n",
    "\n",
    "\n",
    "# Alternative version with more robust error handling\n",
    "def icc_oj_fun_robust(data):\n",
    "    \"\"\"\n",
    "    Calculate Ohlson-Juettner (2005) implied cost of capital with robust error handling.\n",
    "    \"\"\"\n",
    "    # Required columns\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'po', 'prc_adj', 'rf10', \n",
    "                     'id', 'datadate']\n",
    "    \n",
    "    # Validate input\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter and copy data\n",
    "    mask = (data['eps1'].notna() & \n",
    "            data['eps2'].notna() & \n",
    "            data['ltg'].notna() & \n",
    "            data['po'].notna() &\n",
    "            data['prc_adj'].notna() & \n",
    "            data['rf10'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        # Return empty DataFrame with correct structure\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_oj'])\n",
    "    \n",
    "    oj = data.loc[mask, required_cols].copy()\n",
    "    \n",
    "    # Handle potential division by zero\n",
    "    if (oj['prc_adj'] == 0).any():\n",
    "        print(\"Warning: Zero prices detected, filtering them out\")\n",
    "        oj = oj[oj['prc_adj'] != 0]\n",
    "    \n",
    "    if (oj['eps1'] == 0).any():\n",
    "        print(\"Warning: Zero EPS1 detected, filtering them out\")\n",
    "        oj = oj[oj['eps1'] != 0]\n",
    "    \n",
    "    if len(oj) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_oj'])\n",
    "    \n",
    "    # Calculations\n",
    "    oj['gam_min1'] = oj['rf10'] - 0.03\n",
    "    oj['A'] = 0.5 * (oj['gam_min1'] + oj['eps1'] * oj['po'] / oj['prc_adj'])\n",
    "    \n",
    "    # Short-term growth calculation with NaN handling\n",
    "    growth_ratio = (oj['eps2'] - oj['eps1']) / oj['eps1']\n",
    "    stg_calc = (growth_ratio * oj['ltg']) ** 0.5\n",
    "    \n",
    "    # Handle negative values under square root\n",
    "    stg_calc = np.where(growth_ratio * oj['ltg'] >= 0, stg_calc, np.nan)\n",
    "    oj['stg'] = np.maximum(stg_calc, oj['ltg'])\n",
    "    \n",
    "    # ICC calculation with error handling\n",
    "    discriminant = (oj['A']**2 + \n",
    "                   oj['eps1'] / oj['prc_adj'] * (oj['stg'] - oj['gam_min1']))\n",
    "    \n",
    "    # Handle negative discriminant\n",
    "    discriminant = np.maximum(discriminant, 0)\n",
    "    \n",
    "    oj['icc_oj'] = oj['A'] + np.sqrt(discriminant)\n",
    "    \n",
    "    # Filter out any remaining NaN or infinite results\n",
    "    result = oj[['id', 'datadate', 'icc_oj']].copy()\n",
    "    result = result[np.isfinite(result['icc_oj'])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage and testing function\n",
    "def test_icc_oj():\n",
    "    \"\"\"Test function with sample data\"\"\"\n",
    "    # Create sample data\n",
    "    np.random.seed(42)\n",
    "    n = 1000\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'id': range(n),\n",
    "        'datadate': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "        'eps1': np.random.uniform(0.5, 3.0, n),\n",
    "        'eps2': np.random.uniform(0.6, 3.5, n),\n",
    "        'ltg': np.random.uniform(0.02, 0.15, n),\n",
    "        'po': np.random.uniform(0.0, 0.8, n),\n",
    "        'prc_adj': np.random.uniform(10, 100, n),\n",
    "        'rf10': np.random.uniform(0.01, 0.05, n)\n",
    "    })\n",
    "    \n",
    "    # Add some missing values to test handling\n",
    "    test_data.loc[np.random.choice(n, 50, replace=False), 'eps1'] = np.nan\n",
    "    test_data.loc[np.random.choice(n, 30, replace=False), 'ltg'] = np.nan\n",
    "    \n",
    "    # Test the function\n",
    "    result = icc_oj_fun_robust(test_data)\n",
    "    \n",
    "    print(f\"Input rows: {len(test_data)}\")\n",
    "    print(f\"Output rows: {len(result)}\")\n",
    "    print(f\"Average ICC_OJ: {result['icc_oj'].mean():.4f}\")\n",
    "    print(f\"ICC_OJ range: {result['icc_oj'].min():.4f} to {result['icc_oj'].max():.4f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run test\n",
    "    test_result = test_icc_oj()\n",
    "    print(\"\\nFirst 5 results:\")\n",
    "    print(test_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b0956",
   "metadata": {},
   "source": [
    "## PEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db32200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input rows: 1000\n",
      "Output rows: 551\n",
      "Average ICC_PEG: 0.0837\n",
      "ICC_PEG range: 0.0212 to 0.2345\n",
      "\n",
      "First 5 results:\n",
      "   id   datadate   icc_peg\n",
      "2   2 2020-01-03  0.124860\n",
      "3   3 2020-01-04  0.064534\n",
      "4   4 2020-01-05  0.071901\n",
      "5   5 2020-01-06  0.069790\n",
      "6   6 2020-01-07  0.058677\n"
     ]
    }
   ],
   "source": [
    "def icc_peg_fun(data):\n",
    "    \"\"\"\n",
    "    Calculate PEG (Easton 2004, Mohanram and Gode) implied cost of capital.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame containing required variables: eps1, eps2, ltg, \n",
    "        prc_adj, id, datadate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with id, datadate, and icc_peg columns\n",
    "    \"\"\"\n",
    "    # Required columns for PEG model\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'prc_adj', 'id', 'datadate']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter rows where required variables are not null\n",
    "    peg = data.dropna(subset=['eps1', 'eps2', 'ltg'])[\n",
    "        ['id', 'datadate', 'prc_adj', 'eps1', 'eps2', 'ltg']\n",
    "    ].copy()\n",
    "    \n",
    "    # Short-term growth rate calculation\n",
    "    # Max ensures that STG >= LTG (see p. 450 of Mohanram and Gode)\n",
    "    stg_calc = ((peg['eps2'] - peg['eps1']) / peg['eps1'] * peg['ltg']) ** 0.5\n",
    "    peg['stg'] = np.maximum(stg_calc, peg['ltg'])\n",
    "    \n",
    "    # PEG ICC calculation (simplified Easton model)\n",
    "    peg['icc_peg'] = np.sqrt(peg['eps1'] / peg['prc_adj'] * peg['stg'])\n",
    "    \n",
    "    # Return only required columns\n",
    "    return peg[['id', 'datadate', 'icc_peg']]\n",
    "\n",
    "\n",
    "# Robust version with error handling\n",
    "def icc_peg_fun_robust(data):\n",
    "    \"\"\"\n",
    "    Calculate PEG implied cost of capital with robust error handling.\n",
    "    \"\"\"\n",
    "    # Required columns\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'prc_adj', 'id', 'datadate']\n",
    "    \n",
    "    # Validate input\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter and copy data\n",
    "    mask = (data['eps1'].notna() & \n",
    "            data['eps2'].notna() & \n",
    "            data['ltg'].notna() &\n",
    "            data['prc_adj'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_peg'])\n",
    "    \n",
    "    peg = data.loc[mask, required_cols].copy()\n",
    "    \n",
    "    # Handle potential division by zero\n",
    "    if (peg['prc_adj'] == 0).any():\n",
    "        print(\"Warning: Zero prices detected, filtering them out\")\n",
    "        peg = peg[peg['prc_adj'] != 0]\n",
    "    \n",
    "    if (peg['eps1'] == 0).any():\n",
    "        print(\"Warning: Zero EPS1 detected, filtering them out\")\n",
    "        peg = peg[peg['eps1'] != 0]\n",
    "    \n",
    "    if len(peg) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_peg'])\n",
    "    \n",
    "    # Short-term growth calculation with error handling\n",
    "    growth_ratio = (peg['eps2'] - peg['eps1']) / peg['eps1']\n",
    "    stg_calc = (growth_ratio * peg['ltg']) ** 0.5\n",
    "    \n",
    "    # Handle negative values under square root\n",
    "    stg_calc = np.where(growth_ratio * peg['ltg'] >= 0, stg_calc, np.nan)\n",
    "    peg['stg'] = np.maximum(stg_calc, peg['ltg'])\n",
    "    \n",
    "    # PEG ICC calculation with error handling\n",
    "    earnings_yield_growth = peg['eps1'] / peg['prc_adj'] * peg['stg']\n",
    "    \n",
    "    # Handle negative values under square root\n",
    "    earnings_yield_growth = np.maximum(earnings_yield_growth, 0)\n",
    "    \n",
    "    peg['icc_peg'] = np.sqrt(earnings_yield_growth)\n",
    "    \n",
    "    # Filter out any remaining NaN or infinite results\n",
    "    result = peg[['id', 'datadate', 'icc_peg']].copy()\n",
    "    result = result[np.isfinite(result['icc_peg'])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_icc_peg():\n",
    "    \"\"\"Test function with sample data\"\"\"\n",
    "    # Create sample data\n",
    "    np.random.seed(42)\n",
    "    n = 1000\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'id': range(n),\n",
    "        'datadate': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "        'eps1': np.random.uniform(0.5, 3.0, n),\n",
    "        'eps2': np.random.uniform(0.6, 3.5, n),\n",
    "        'ltg': np.random.uniform(0.02, 0.15, n),\n",
    "        'prc_adj': np.random.uniform(10, 100, n)\n",
    "    })\n",
    "    \n",
    "    # Add some missing values to test handling\n",
    "    test_data.loc[np.random.choice(n, 50, replace=False), 'eps1'] = np.nan\n",
    "    test_data.loc[np.random.choice(n, 30, replace=False), 'ltg'] = np.nan\n",
    "    \n",
    "    # Test the function\n",
    "    result = icc_peg_fun_robust(test_data)\n",
    "    \n",
    "    print(f\"Input rows: {len(test_data)}\")\n",
    "    print(f\"Output rows: {len(result)}\")\n",
    "    print(f\"Average ICC_PEG: {result['icc_peg'].mean():.4f}\")\n",
    "    print(f\"ICC_PEG range: {result['icc_peg'].min():.4f} to {result['icc_peg'].max():.4f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run test\n",
    "    test_result = test_icc_peg()\n",
    "    print(\"\\nFirst 5 results:\")\n",
    "    print(test_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5896ed",
   "metadata": {},
   "source": [
    "## Gebhardt-Lee-Swaminathan (2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16603f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input rows: 100\n",
      "Output rows: 98\n",
      "Average ICC_GLS: 0.0971\n",
      "ICC_GLS range: 0.0114 to 0.3091\n",
      "\n",
      "First 5 results:\n",
      "   id   datadate   icc_gls\n",
      "0   0 2020-01-01  0.182016\n",
      "1   1 2020-01-02  0.041466\n",
      "2   2 2020-01-03  0.037690\n",
      "3   3 2020-01-04  0.105928\n",
      "4   4 2020-01-05  0.093460\n"
     ]
    }
   ],
   "source": [
    "def icc_gls_fun(data, root_low=0.01, root_high=0.5):\n",
    "    \"\"\"\n",
    "    Calculate Gebhardt, Lee, and Swaminathan (2001) implied cost of capital.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame containing required variables: eps1, eps2, bps0, prc_adj, \n",
    "        po, roe_ind, id, datadate\n",
    "    root_low : float, default=0.01\n",
    "        Lower bound for root finding\n",
    "    root_high : float, default=0.5\n",
    "        Upper bound for root finding\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with id, datadate, and icc_gls columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Required columns\n",
    "    required_cols = ['eps1', 'eps2', 'bps0', 'prc_adj', 'po', 'roe_ind', \n",
    "                     'id', 'datadate']\n",
    "    \n",
    "    # Validate input\n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter and copy data\n",
    "    mask = (data['eps1'].notna() & \n",
    "            data['eps2'].notna() & \n",
    "            data['bps0'].notna() &\n",
    "            data['prc_adj'].notna() & \n",
    "            data['po'].notna() &\n",
    "            data['roe_ind'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_gls'])\n",
    "    \n",
    "    gls = data.loc[mask, required_cols].copy()\n",
    "    \n",
    "    # Additional filtering for infinite values and positive book values\n",
    "    gls = gls[np.isfinite(gls['eps1']) & \n",
    "              np.isfinite(gls['bps0']) & \n",
    "              (gls['bps0'] > 0)]\n",
    "    \n",
    "    if len(gls) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_gls'])\n",
    "    \n",
    "    # Forward projections for years 1-2\n",
    "    gls['bps1'] = gls['bps0'] + gls['eps1'] * (1 - gls['po'])\n",
    "    gls['bps2'] = gls['bps1'] + gls['eps2'] * (1 - gls['po'])\n",
    "    gls['roe1'] = gls['eps1'] / gls['bps0']\n",
    "    gls['roe2'] = gls['eps2'] / gls['bps1']\n",
    "    \n",
    "    # Linear convergence parameter to industry ROE over 10 years\n",
    "    gls['g'] = (gls['roe_ind'] - gls['roe2']) / 10\n",
    "    \n",
    "    # Project years 3-12\n",
    "    for h in range(3, 13):  # 3 to 12 inclusive\n",
    "        # ROE converges linearly to industry average\n",
    "        gls[f'roe{h}'] = gls['roe2'] + gls['g'] * (h - 2)\n",
    "        \n",
    "        # Book value grows with retained earnings\n",
    "        gls[f'bps{h}'] = gls[f'bps{h-1}'] * (1 + gls[f'roe{h}'] * (1 - gls['po']))\n",
    "    \n",
    "    def gls_func(r, p, bps0, bps1, bps2, bps3, bps4, bps5, bps6, bps7, \n",
    "                 bps8, bps9, bps10, bps11, roe1, roe2, roe3, roe4, roe5, \n",
    "                 roe6, roe7, roe8, roe9, roe10, roe11, roe12):\n",
    "        \"\"\"\n",
    "        Residual income valuation function.\n",
    "        Returns price minus theoretical value (should be zero at correct r).\n",
    "        \"\"\"\n",
    "        residual_income = (\n",
    "            ((roe1 - r) * bps0) / (1 + r)**1 +\n",
    "            ((roe2 - r) * bps1) / (1 + r)**2 +\n",
    "            ((roe3 - r) * bps2) / (1 + r)**3 +\n",
    "            ((roe4 - r) * bps3) / (1 + r)**4 +\n",
    "            ((roe5 - r) * bps4) / (1 + r)**5 +\n",
    "            ((roe6 - r) * bps5) / (1 + r)**6 +\n",
    "            ((roe7 - r) * bps6) / (1 + r)**7 +\n",
    "            ((roe8 - r) * bps7) / (1 + r)**8 +\n",
    "            ((roe9 - r) * bps8) / (1 + r)**9 +\n",
    "            ((roe10 - r) * bps9) / (1 + r)**10 +\n",
    "            ((roe11 - r) * bps10) / (1 + r)**11 +  # FIXED: was bps11\n",
    "            ((roe12 - r) * bps11) / (r * (1 + r)**11)  # Terminal value\n",
    "        )\n",
    "        \n",
    "        theoretical_price = bps0 + residual_income\n",
    "        return p - theoretical_price\n",
    "    \n",
    "    # Check interval validity and solve\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in gls.iterrows():\n",
    "        try:\n",
    "            # Test interval bounds\n",
    "            int_low = gls_func(\n",
    "                r=root_low, p=row['prc_adj'],\n",
    "                bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                bps3=row['bps3'], bps4=row['bps4'], bps5=row['bps5'],\n",
    "                bps6=row['bps6'], bps7=row['bps7'], bps8=row['bps8'], \n",
    "                bps9=row['bps9'], bps10=row['bps10'], bps11=row['bps11'],\n",
    "                roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                roe4=row['roe4'], roe5=row['roe5'], roe6=row['roe6'],\n",
    "                roe7=row['roe7'], roe8=row['roe8'], roe9=row['roe9'], \n",
    "                roe10=row['roe10'], roe11=row['roe11'], roe12=row['roe12']\n",
    "            )\n",
    "            \n",
    "            int_high = gls_func(\n",
    "                r=root_high, p=row['prc_adj'],\n",
    "                bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                bps3=row['bps3'], bps4=row['bps4'], bps5=row['bps5'],\n",
    "                bps6=row['bps6'], bps7=row['bps7'], bps8=row['bps8'], \n",
    "                bps9=row['bps9'], bps10=row['bps10'], bps11=row['bps11'],\n",
    "                roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                roe4=row['roe4'], roe5=row['roe5'], roe6=row['roe6'],\n",
    "                roe7=row['roe7'], roe8=row['roe8'], roe9=row['roe9'], \n",
    "                roe10=row['roe10'], roe11=row['roe11'], roe12=row['roe12']\n",
    "            )\n",
    "            \n",
    "            # Check if root exists in interval (opposite signs)\n",
    "            if np.sign(int_low) != np.sign(int_high) and not np.isnan(int_low):\n",
    "                # Solve for ICC using scipy's brentq (more robust than uniroot)\n",
    "                from scipy.optimize import brentq\n",
    "                \n",
    "                def objective(r):\n",
    "                    return gls_func(\n",
    "                        r=r, p=row['prc_adj'],\n",
    "                        bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                        bps3=row['bps3'], bps4=row['bps4'], bps5=row['bps5'],\n",
    "                        bps6=row['bps6'], bps7=row['bps7'], bps8=row['bps8'], \n",
    "                        bps9=row['bps9'], bps10=row['bps10'], bps11=row['bps11'],\n",
    "                        roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                        roe4=row['roe4'], roe5=row['roe5'], roe6=row['roe6'],\n",
    "                        roe7=row['roe7'], roe8=row['roe8'], roe9=row['roe9'], \n",
    "                        roe10=row['roe10'], roe11=row['roe11'], roe12=row['roe12']\n",
    "                    )\n",
    "                \n",
    "                icc_value = brentq(objective, root_low, root_high)\n",
    "                \n",
    "                results.append({\n",
    "                    'id': row['id'],\n",
    "                    'datadate': row['datadate'],\n",
    "                    'icc_gls': icc_value\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Skip problematic cases\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Robust version with vectorized operations (faster for large datasets)\n",
    "def icc_gls_fun_vectorized(data, root_low=0.01, root_high=0.5, max_workers=4):\n",
    "    \"\"\"\n",
    "    Vectorized version using parallel processing for better performance.\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "    from scipy.optimize import brentq\n",
    "    \n",
    "    # Same initial setup as above...\n",
    "    required_cols = ['eps1', 'eps2', 'bps0', 'prc_adj', 'po', 'roe_ind', \n",
    "                     'id', 'datadate']\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    mask = (data['eps1'].notna() & data['eps2'].notna() & \n",
    "            data['bps0'].notna() & data['prc_adj'].notna() & \n",
    "            data['po'].notna() & data['roe_ind'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_gls'])\n",
    "    \n",
    "    gls = data.loc[mask, required_cols].copy()\n",
    "    gls = gls[np.isfinite(gls['eps1']) & \n",
    "              np.isfinite(gls['bps0']) & \n",
    "              (gls['bps0'] > 0)]\n",
    "    \n",
    "    if len(gls) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_gls'])\n",
    "    \n",
    "    # Same projections...\n",
    "    gls['bps1'] = gls['bps0'] + gls['eps1'] * (1 - gls['po'])\n",
    "    gls['bps2'] = gls['bps1'] + gls['eps2'] * (1 - gls['po'])\n",
    "    gls['roe1'] = gls['eps1'] / gls['bps0']\n",
    "    gls['roe2'] = gls['eps2'] / gls['bps1']\n",
    "    gls['g'] = (gls['roe_ind'] - gls['roe2']) / 10\n",
    "    \n",
    "    for h in range(3, 13):\n",
    "        gls[f'roe{h}'] = gls['roe2'] + gls['g'] * (h - 2)\n",
    "        gls[f'bps{h}'] = gls[f'bps{h-1}'] * (1 + gls[f'roe{h}'] * (1 - gls['po']))\n",
    "    \n",
    "    def solve_single_row(row_tuple):\n",
    "        \"\"\"Helper function for parallel processing\"\"\"\n",
    "        idx, row = row_tuple\n",
    "        try:\n",
    "            def objective(r):\n",
    "                residual_income = (\n",
    "                    ((row['roe1'] - r) * row['bps0']) / (1 + r)**1 +\n",
    "                    ((row['roe2'] - r) * row['bps1']) / (1 + r)**2 +\n",
    "                    ((row['roe3'] - r) * row['bps2']) / (1 + r)**3 +\n",
    "                    ((row['roe4'] - r) * row['bps3']) / (1 + r)**4 +\n",
    "                    ((row['roe5'] - r) * row['bps4']) / (1 + r)**5 +\n",
    "                    ((row['roe6'] - r) * row['bps5']) / (1 + r)**6 +\n",
    "                    ((row['roe7'] - r) * row['bps6']) / (1 + r)**7 +\n",
    "                    ((row['roe8'] - r) * row['bps7']) / (1 + r)**8 +\n",
    "                    ((row['roe9'] - r) * row['bps8']) / (1 + r)**9 +\n",
    "                    ((row['roe10'] - r) * row['bps9']) / (1 + r)**10 +\n",
    "                    ((row['roe11'] - r) * row['bps10']) / (1 + r)**11 +\n",
    "                    ((row['roe12'] - r) * row['bps11']) / (r * (1 + r)**11)\n",
    "                )\n",
    "                return row['prc_adj'] - (row['bps0'] + residual_income)\n",
    "            \n",
    "            # Test bounds\n",
    "            if np.sign(objective(root_low)) != np.sign(objective(root_high)):\n",
    "                icc_value = brentq(objective, root_low, root_high)\n",
    "                return {\n",
    "                    'id': row['id'],\n",
    "                    'datadate': row['datadate'],\n",
    "                    'icc_gls': icc_value\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    # Parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(solve_single_row, gls.iterrows()))\n",
    "    \n",
    "    # Filter out None results\n",
    "    results = [r for r in results if r is not None]\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_icc_gls():\n",
    "    \"\"\"Test function with sample data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n = 100\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'id': range(n),\n",
    "        'datadate': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "        'eps1': np.random.uniform(0.5, 3.0, n),\n",
    "        'eps2': np.random.uniform(0.6, 3.5, n),\n",
    "        'bps0': np.random.uniform(5, 50, n),\n",
    "        'prc_adj': np.random.uniform(10, 100, n),\n",
    "        'po': np.random.uniform(0.0, 0.8, n),\n",
    "        'roe_ind': np.random.uniform(0.05, 0.25, n)\n",
    "    })\n",
    "    \n",
    "    # Test the function\n",
    "    result = icc_gls_fun(test_data)\n",
    "    \n",
    "    print(f\"Input rows: {len(test_data)}\")\n",
    "    print(f\"Output rows: {len(result)}\")\n",
    "    if len(result) > 0:\n",
    "        print(f\"Average ICC_GLS: {result['icc_gls'].mean():.4f}\")\n",
    "        print(f\"ICC_GLS range: {result['icc_gls'].min():.4f} to {result['icc_gls'].max():.4f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run test\n",
    "    test_result = test_icc_gls()\n",
    "    if len(test_result) > 0:\n",
    "        print(\"\\nFirst 5 results:\")\n",
    "        print(test_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc25eb",
   "metadata": {},
   "source": [
    "## Claus-Thomas (2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4418e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CT ICC Function:\n",
      "==================================================\n",
      "Input rows: 100\n",
      "Output rows: 97\n",
      "Average ICC_CT: 0.0601\n",
      "ICC_CT range: 0.0107 to 0.2422\n",
      "Success rate: 97.00%\n",
      "\n",
      "==================================================\n",
      "Comparing ICC Methods:\n",
      "==================================================\n",
      "CT Model Characteristics:\n",
      "- Uses 5-year explicit forecasting period\n",
      "- Terminal value with growing perpetuity\n",
      "- Risk premium g = rf10 - 3%\n",
      "- Automatic constraint handling (r > g)\n",
      "\n",
      "Results: 50 successful calculations out of 50\n",
      "Mean ICC: 0.0580\n",
      "Std ICC: 0.0275\n",
      "\n",
      "First 5 CT results:\n",
      "   id   datadate    icc_ct\n",
      "0   0 2020-01-01  0.045435\n",
      "1   1 2020-01-02  0.017534\n",
      "2   2 2020-01-03  0.025867\n",
      "3   3 2020-01-04  0.026378\n",
      "4   4 2020-01-05  0.088572\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "import warnings\n",
    "\n",
    "def icc_ct_fun(data, root_low=0.01, root_high=0.5):\n",
    "    \"\"\"\n",
    "    Calculate Claus and Thomas (2001) implied cost of capital.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame containing required variables: eps1, eps2, ltg, bps0, \n",
    "        prc_adj, po, roe_ind, rf10, id, datadate\n",
    "    root_low : float, default=0.01\n",
    "        Lower bound for root finding\n",
    "    root_high : float, default=0.5\n",
    "        Upper bound for root finding\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with id, datadate, and icc_ct columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Required columns\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'bps0', 'prc_adj', 'po', \n",
    "                     'roe_ind', 'rf10', 'id', 'datadate']\n",
    "    \n",
    "    # Validate input\n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Filter and copy data\n",
    "    mask = (data['eps1'].notna() & \n",
    "            data['eps2'].notna() & \n",
    "            data['ltg'].notna() &\n",
    "            data['bps0'].notna() &\n",
    "            data['prc_adj'].notna() & \n",
    "            data['po'].notna() &\n",
    "            data['roe_ind'].notna() &\n",
    "            data['rf10'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_ct'])\n",
    "    \n",
    "    ct = data.loc[mask, required_cols].copy()\n",
    "    \n",
    "    # Additional filtering for infinite values and positive book values\n",
    "    ct = ct[np.isfinite(ct['eps1']) & \n",
    "            np.isfinite(ct['bps0']) & \n",
    "            (ct['bps0'] > 0)]\n",
    "    \n",
    "    if len(ct) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_ct'])\n",
    "    \n",
    "    # Calculate risk premium (g)\n",
    "    ct['g'] = ct['rf10'] - 0.03\n",
    "    \n",
    "    # Forward projections for years 1-2\n",
    "    ct['bps1'] = ct['bps0'] + ct['eps1'] * (1 - ct['po'])\n",
    "    ct['bps2'] = ct['bps1'] + ct['eps2'] * (1 - ct['po'])\n",
    "    ct['roe1'] = ct['eps1'] / ct['bps0']\n",
    "    ct['roe2'] = ct['eps2'] / ct['bps1']\n",
    "    \n",
    "    # Project years 3-5 with constant LTG growth\n",
    "    for h in range(3, 6):  # 3 to 5 inclusive\n",
    "        # EPS grows at LTG rate\n",
    "        ct[f'eps{h}'] = ct[f'eps{h-1}'] * (1 + ct['ltg'])\n",
    "        \n",
    "        # ROE calculation\n",
    "        ct[f'roe{h}'] = ct[f'eps{h}'] / ct[f'bps{h-1}']\n",
    "        \n",
    "        # Book value evolution\n",
    "        ct[f'bps{h}'] = ct[f'bps{h-1}'] + ct[f'eps{h}'] * (1 - ct['po'])\n",
    "    \n",
    "    def ct_func(r, p, g, bps0, bps1, bps2, bps3, bps4, \n",
    "                roe1, roe2, roe3, roe4, roe5):\n",
    "        \"\"\"\n",
    "        CT residual income valuation function.\n",
    "        Returns price minus theoretical value (should be zero at correct r).\n",
    "        \"\"\"\n",
    "        # Residual income for years 1-5\n",
    "        residual_income = (\n",
    "            ((roe1 - r) * bps0) / (1 + r)**1 +\n",
    "            ((roe2 - r) * bps1) / (1 + r)**2 +\n",
    "            ((roe3 - r) * bps2) / (1 + r)**3 +\n",
    "            ((roe4 - r) * bps3) / (1 + r)**4 +\n",
    "            ((roe5 - r) * bps4) / (1 + r)**5\n",
    "        )\n",
    "        \n",
    "        # Terminal value (growing perpetuity from year 6)\n",
    "        # Avoid division by zero when r  g\n",
    "        if abs(r - g) < 1e-10:\n",
    "            terminal_value = 0\n",
    "        else:\n",
    "            terminal_value = ((roe5 - r) * (1 + g) * bps4) / ((r - g) * (1 + r)**5)\n",
    "        \n",
    "        theoretical_price = bps0 + residual_income + terminal_value\n",
    "        return p - theoretical_price\n",
    "    \n",
    "    # Check interval validity and solve\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in ct.iterrows():\n",
    "        try:\n",
    "            # Ensure r > g to avoid terminal value singularity\n",
    "            r_low = max(root_low, row['g'] + 0.001)\n",
    "            \n",
    "            # Test interval bounds\n",
    "            int_low = ct_func(\n",
    "                r=r_low, p=row['prc_adj'], g=row['g'],\n",
    "                bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                bps3=row['bps3'], bps4=row['bps4'],\n",
    "                roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                roe4=row['roe4'], roe5=row['roe5']\n",
    "            )\n",
    "            \n",
    "            int_high = ct_func(\n",
    "                r=root_high, p=row['prc_adj'], g=row['g'],\n",
    "                bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                bps3=row['bps3'], bps4=row['bps4'],\n",
    "                roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                roe4=row['roe4'], roe5=row['roe5']\n",
    "            )\n",
    "            \n",
    "            # Check if root exists in interval (opposite signs)\n",
    "            if (np.sign(int_low) != np.sign(int_high) and \n",
    "                not np.isnan(int_low) and not np.isnan(int_high)):\n",
    "                \n",
    "                # Solve for ICC\n",
    "                def objective(r):\n",
    "                    return ct_func(\n",
    "                        r=r, p=row['prc_adj'], g=row['g'],\n",
    "                        bps0=row['bps0'], bps1=row['bps1'], bps2=row['bps2'], \n",
    "                        bps3=row['bps3'], bps4=row['bps4'],\n",
    "                        roe1=row['roe1'], roe2=row['roe2'], roe3=row['roe3'], \n",
    "                        roe4=row['roe4'], roe5=row['roe5']\n",
    "                    )\n",
    "                \n",
    "                icc_value = brentq(objective, r_low, root_high)\n",
    "                \n",
    "                results.append({\n",
    "                    'id': row['id'],\n",
    "                    'datadate': row['datadate'],\n",
    "                    'icc_ct': icc_value\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Skip problematic cases\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Vectorized version for better performance with large datasets\n",
    "def icc_ct_fun_vectorized(data, root_low=0.01, root_high=0.5, max_workers=4):\n",
    "    \"\"\"\n",
    "    Vectorized version using parallel processing for better performance.\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "    \n",
    "    # Same initial setup as above...\n",
    "    required_cols = ['eps1', 'eps2', 'ltg', 'bps0', 'prc_adj', 'po', \n",
    "                     'roe_ind', 'rf10', 'id', 'datadate']\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    mask = (data['eps1'].notna() & data['eps2'].notna() & \n",
    "            data['ltg'].notna() & data['bps0'].notna() & \n",
    "            data['prc_adj'].notna() & data['po'].notna() & \n",
    "            data['roe_ind'].notna() & data['rf10'].notna())\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_ct'])\n",
    "    \n",
    "    ct = data.loc[mask, required_cols].copy()\n",
    "    ct = ct[np.isfinite(ct['eps1']) & \n",
    "            np.isfinite(ct['bps0']) & \n",
    "            (ct['bps0'] > 0)]\n",
    "    \n",
    "    if len(ct) == 0:\n",
    "        return pd.DataFrame(columns=['id', 'datadate', 'icc_ct'])\n",
    "    \n",
    "    # Same projections...\n",
    "    ct['g'] = ct['rf10'] - 0.03\n",
    "    ct['bps1'] = ct['bps0'] + ct['eps1'] * (1 - ct['po'])\n",
    "    ct['bps2'] = ct['bps1'] + ct['eps2'] * (1 - ct['po'])\n",
    "    ct['roe1'] = ct['eps1'] / ct['bps0']\n",
    "    ct['roe2'] = ct['eps2'] / ct['bps1']\n",
    "    \n",
    "    for h in range(3, 6):\n",
    "        ct[f'eps{h}'] = ct[f'eps{h-1}'] * (1 + ct['ltg'])\n",
    "        ct[f'roe{h}'] = ct[f'eps{h}'] / ct[f'bps{h-1}']\n",
    "        ct[f'bps{h}'] = ct[f'bps{h-1}'] + ct[f'eps{h}'] * (1 - ct['po'])\n",
    "    \n",
    "    def solve_single_row(row_tuple):\n",
    "        \"\"\"Helper function for parallel processing\"\"\"\n",
    "        idx, row = row_tuple\n",
    "        try:\n",
    "            def objective(r):\n",
    "                # Residual income for years 1-5\n",
    "                residual_income = (\n",
    "                    ((row['roe1'] - r) * row['bps0']) / (1 + r)**1 +\n",
    "                    ((row['roe2'] - r) * row['bps1']) / (1 + r)**2 +\n",
    "                    ((row['roe3'] - r) * row['bps2']) / (1 + r)**3 +\n",
    "                    ((row['roe4'] - r) * row['bps3']) / (1 + r)**4 +\n",
    "                    ((row['roe5'] - r) * row['bps4']) / (1 + r)**5\n",
    "                )\n",
    "                \n",
    "                # Terminal value\n",
    "                if abs(r - row['g']) < 1e-10:\n",
    "                    terminal_value = 0\n",
    "                else:\n",
    "                    terminal_value = ((row['roe5'] - r) * (1 + row['g']) * row['bps4']) / ((r - row['g']) * (1 + r)**5)\n",
    "                \n",
    "                return row['prc_adj'] - (row['bps0'] + residual_income + terminal_value)\n",
    "            \n",
    "            # Test bounds\n",
    "            r_low = max(root_low, row['g'] + 0.001)\n",
    "            \n",
    "            if np.sign(objective(r_low)) != np.sign(objective(root_high)):\n",
    "                icc_value = brentq(objective, r_low, root_high)\n",
    "                return {\n",
    "                    'id': row['id'],\n",
    "                    'datadate': row['datadate'],\n",
    "                    'icc_ct': icc_value\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    # Parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(solve_single_row, ct.iterrows()))\n",
    "    \n",
    "    # Filter out None results\n",
    "    results = [r for r in results if r is not None]\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_icc_ct():\n",
    "    \"\"\"Test function with sample data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n = 100\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'id': range(n),\n",
    "        'datadate': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "        'eps1': np.random.uniform(0.5, 3.0, n),\n",
    "        'eps2': np.random.uniform(0.6, 3.5, n),\n",
    "        'ltg': np.random.uniform(0.02, 0.15, n),  # 2% to 15% growth\n",
    "        'bps0': np.random.uniform(5, 50, n),\n",
    "        'prc_adj': np.random.uniform(10, 100, n),\n",
    "        'po': np.random.uniform(0.0, 0.8, n),\n",
    "        'roe_ind': np.random.uniform(0.05, 0.25, n),\n",
    "        'rf10': np.random.uniform(0.01, 0.05, n)  # 1% to 5% risk-free rate\n",
    "    })\n",
    "    \n",
    "    # Test the function\n",
    "    result = icc_ct_fun(test_data)\n",
    "    \n",
    "    print(f\"Input rows: {len(test_data)}\")\n",
    "    print(f\"Output rows: {len(result)}\")\n",
    "    if len(result) > 0:\n",
    "        print(f\"Average ICC_CT: {result['icc_ct'].mean():.4f}\")\n",
    "        print(f\"ICC_CT range: {result['icc_ct'].min():.4f} to {result['icc_ct'].max():.4f}\")\n",
    "        print(f\"Success rate: {len(result)/len(test_data):.2%}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Comparison function to show differences between CT and other methods\n",
    "def compare_icc_methods():\n",
    "    \"\"\"Compare CT model with simplified versions\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n = 50\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'id': range(n),\n",
    "        'datadate': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "        'eps1': np.random.uniform(1.0, 3.0, n),\n",
    "        'eps2': np.random.uniform(1.2, 3.5, n),\n",
    "        'ltg': np.random.uniform(0.05, 0.12, n),\n",
    "        'bps0': np.random.uniform(10, 30, n),\n",
    "        'prc_adj': np.random.uniform(20, 80, n),\n",
    "        'po': np.random.uniform(0.2, 0.6, n),\n",
    "        'roe_ind': np.random.uniform(0.08, 0.18, n),\n",
    "        'rf10': np.random.uniform(0.02, 0.04, n)\n",
    "    })\n",
    "    \n",
    "    # Calculate CT ICC\n",
    "    ct_result = icc_ct_fun(test_data)\n",
    "    \n",
    "    print(\"CT Model Characteristics:\")\n",
    "    print(f\"- Uses 5-year explicit forecasting period\")\n",
    "    print(f\"- Terminal value with growing perpetuity\")\n",
    "    print(f\"- Risk premium g = rf10 - 3%\")\n",
    "    print(f\"- Automatic constraint handling (r > g)\")\n",
    "    print(f\"\\nResults: {len(ct_result)} successful calculations out of {len(test_data)}\")\n",
    "    \n",
    "    if len(ct_result) > 0:\n",
    "        print(f\"Mean ICC: {ct_result['icc_ct'].mean():.4f}\")\n",
    "        print(f\"Std ICC: {ct_result['icc_ct'].std():.4f}\")\n",
    "    \n",
    "    return ct_result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run tests\n",
    "    print(\"Testing CT ICC Function:\")\n",
    "    print(\"=\" * 50)\n",
    "    test_result = test_icc_ct()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Comparing ICC Methods:\")\n",
    "    print(\"=\" * 50)\n",
    "    comparison_result = compare_icc_methods()\n",
    "    \n",
    "    if len(test_result) > 0:\n",
    "        print(\"\\nFirst 5 CT results:\")\n",
    "        print(test_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363df9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
